{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": "Welcome to exercise one of \u201cApache Spark for Scalable Machine Learning on BigData\u201d. In this exercise you\u2019ll apply the basics of functional and parallel programming. \n\nLet\u2019s start with a simple example. Let\u2019s consider you have a list of integers.\n\nLet\u2019s find out what the size of this list is.\n\nNote that we already provide an RDD object, so please have a look at the RDD API in order to find out what function to use:\nhttps://spark.apache.org/docs/latest/api/python/pyspark.html#pyspark.RDD\n\nThe following link contains additional documentation:\nhttps://spark.apache.org/docs/latest/rdd-programming-guide.html\n\n"}, {"metadata": {}, "cell_type": "code", "source": "rdd = sc.parallelize(range(100))", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20200214020245-0000\nKERNEL_ID = 33193cee-f6ba-4cba-b771-28e0298669ab\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# please replace $$ with the correct characters\nrdd.count()", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "100"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "You should see \"100\" as answer. Now we want to know the sum of all elements. Please again, have a look at the API documentation and complete the code below in order to get the sum."}, {"metadata": {}, "cell_type": "code", "source": "rdd.sum()", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "4950"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "You should get \"4950\" as answer."}, {"metadata": {}, "cell_type": "code", "source": "rdd.take(10)", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "rdd.collect()", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "[0,\n 1,\n 2,\n 3,\n 4,\n 5,\n 6,\n 7,\n 8,\n 9,\n 10,\n 11,\n 12,\n 13,\n 14,\n 15,\n 16,\n 17,\n 18,\n 19,\n 20,\n 21,\n 22,\n 23,\n 24,\n 25,\n 26,\n 27,\n 28,\n 29,\n 30,\n 31,\n 32,\n 33,\n 34,\n 35,\n 36,\n 37,\n 38,\n 39,\n 40,\n 41,\n 42,\n 43,\n 44,\n 45,\n 46,\n 47,\n 48,\n 49,\n 50,\n 51,\n 52,\n 53,\n 54,\n 55,\n 56,\n 57,\n 58,\n 59,\n 60,\n 61,\n 62,\n 63,\n 64,\n 65,\n 66,\n 67,\n 68,\n 69,\n 70,\n 71,\n 72,\n 73,\n 74,\n 75,\n 76,\n 77,\n 78,\n 79,\n 80,\n 81,\n 82,\n 83,\n 84,\n 85,\n 86,\n 87,\n 88,\n 89,\n 90,\n 91,\n 92,\n 93,\n 94,\n 95,\n 96,\n 97,\n 98,\n 99]"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python36", "display_name": "Python 3.6 with Spark", "language": "python3"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "name": "python", "pygments_lexer": "ipython3", "version": "3.6.8", "file_extension": ".py", "codemirror_mode": {"version": 3, "name": "ipython"}}}, "nbformat": 4, "nbformat_minor": 1}